# -*- coding: utf-8 -*-
# <nbformat>3.0</nbformat>

# <headingcell level=2>

# TP n°10 / DM n°3: Recherche de zéros d'une fonction 

# <codecell>

from math import sin, cos, sqrt, pi, atan

# <headingcell level=3>

# Méthode dichotomique

# <markdowncell>

# **Exercice 1**: On implémente en Python l'algorithme vu en cours:

# <codecell>

def dichotomie(f,a,b,epsilon, verbose=False): 
    iter = 0                                  
    if f(a)*f(b) >= 0:
        return None
    else:
        while abs(a-b) > epsilon:
            m = (a+b)/2.0
            if f(a)*f(m) < 0.0:
                b = m
            else:
                a = m
            if verbose: print("l'intervalle actuel est [",a,b,"]")
            iter+=1
    if verbose: print("le nombre d'iterations est",iter)
    return (a+b)/2.0

# <markdowncell>

# L'argument supplémentaire *verbose* (verbeux) a la valeur par défaut *False* et donc n'affiche pas les intervalles ni le nombre d'itérations. Si on souhaite le faire, il rajouter *verbose=True* ou plus simplement *True*, dans les paramètres de dichotomie lors de son appel (cf plus bas).

# <markdowncell>

# **Exercice 2**: On teste sur la fonction sinus

# <codecell>

taille_table = 52
ligne = "-"*taille_table
print(ligne)
print("| Précision |  val (dichotomie)  | Erreur absolue  |")
print(ligne)
for i in range (16):
    resultat = dichotomie(sin,2.0,4.0,10**(-i))
    erreur = abs(resultat-pi)
    print("| {:.1e}".format(10**-i) + "   | " + "{:.16f}".format(resultat)+ " | "
              + "{:.1e}".format(erreur)+ "         | ")
print(ligne)
print("La valeur de pi est", pi)

# <markdowncell>

# On remarque que si l'on essaie d'augmenter davantage la précision, le programme tourne en boucle sans s'arrêter. 
# 
# Cela est dû au fait que l'on teste la différence de deux flottants dans *while abs(a-b)>epsilon:*, à une précision supérieure à la limitation de la mantisse, qui est de 15 chiffres significatifs.
# 
# On peut le voir avec une boucle:

# <codecell>

i=1
while 1. + 10**(-i) > 1.:
    i += 1
print("1 + 10^(-{:d}) == 1 ----> True".format(i))

# <markdowncell>

# Plus précisément, le module *sys* permet d'accéder à la constante *float_info.epsilon* qui donne la différence entre 1.0 et le flottant le plus proche:

# <codecell>

import sys
sys.float_info.epsilon

# <markdowncell>

# Dans le cours sur la représentation des nombres, nous avions vu qu'en 64 bits, la mantisse était représentée sur 52 bits. Calculons donc 2^(-52):

# <codecell>

2**-52

# <markdowncell>

# Ce qui est bien la même chose. 

# <markdowncell>

# **Exercice 3**: On affiche les intervalles et le nombre d'itérations

# <codecell>

dichotomie(sin,2.0,4.0,10**-4, True)

# <markdowncell>

# **Exercice 4**: Faisons de même pour déterminer le zéro de la fonction $f: x\to x^2-2$ et ainsi en déduire une valeur approchée de $\sqrt{2}$:

# <codecell>

approx = dichotomie(lambda x:x**2-2,0.0,2.0,10**-6)
print('Valeur approchee de sqrt(2): ', approx)
print("Erreur absolue: ",abs(approx-sqrt(2)))

# <headingcell level=3>

# Méthode de Newton

# <markdowncell>

# **Exercice 1**: On implémente en Python l'algorithme vu en cours:

# <codecell>

def newton(f,fprime,u0,epsilon):
    u = u0
    while abs(f(u))>epsilon:
        u = u - f(u)/fprime(u)
    return u

# <markdowncell>

# On peut aussi utiliser la condition de sortie de boucle $|u_{n+1}-u_n|\leq\epsilon$. Les résultats obtenus sont équivalents.
# 
# Dans ce programme, on demande de donner la dérivée *fprime* de *f*. On pourrait aussi la calculer numériquement à partir de *f*, cf cours suivant. 

# <markdowncell>

# **Exercice 2**: On teste sur les exemples précédents:

# <codecell>

newton(sin,cos,4.,10**-6)

# <codecell>

newton(lambda x: x**2-2,lambda x: 2*x,4.,10**-6)

# <markdowncell>

# Pour tester la rapidité des deux méthodes, on utilise la fonction *time* du module *time*

# <codecell>

from time import time

t=time()
dichotomie(sin, 1.0, 4.0, 10**(-15))
print("Le temps de calcul pour la fonction sinus par dichotomie est: ",time()-t)

t=time()
newton(sin,cos,4.0,10**-15)
print("Le temps de calcul pour la fonction sinus par Newton est: ",time()-t)

t=time()
dichotomie(lambda x:x**2-2,0,100.,10**(-15))
print("Le temps de calcul pour la fonction x->x^2-2 par dichotomie est: ",time()-t)

t=time()
newton(lambda x:x**2-2,lambda x:2*x,100.,10**-15)
print("Le temps de calcul pour la fonction x->x^2-2 par Newton est: ",time()-t)

# <markdowncell>

# **Exercice 3**: Calcul des termes des suites pour la dichotomie ($a_n$) et pour Newton ($u_n$).

# <codecell>

def dicholiste(f,a,b,epsilon):
    if f(a)*f(b)>=0.0:
        return None
    else:
        liste_a = [a]
        while abs(a-b)>epsilon:
            m = (a+b)/2
            if f(a)*f(m)<0.0:
                b=m
            else:
                a=m
            liste_a.append(a)
    return liste_a

def newtliste(f,fprime,u0,epsilon):
    u = u0
    liste_u = [u]
    while abs(f(u))>epsilon:
        u=u-f(u)/fprime(u)
        liste_u.append(u)
    return liste_u

# <codecell>

liste_a = dicholiste(lambda x:x**2-2,0,100.,10**(-15)) 

print("La suite des a_n pour la dichotomie est ", liste_a)
print("Cette méthode a nécessité ", len(liste_a), " itérations")

liste_u = newtliste(lambda x:x**2-2,lambda x:2*x,100.,10**(-15)) 

print("La suite des a_n pour la dichotomie est ", liste_u)
print("Cette méthode a nécessité ", len(liste_u), " itérations")

# <markdowncell>

# Le nombre d'itérations nécessaires rejoint la différence de rapidité.

# <markdowncell>

# **Exercice 4**: On s'intéresse à la fonction arctangente

# <markdowncell>

# 1) La fonction arctangente est définie et continue sur $]-\infty,+\infty[$. De plus, $\displaystyle \lim_{x\to -\infty}=-\dfrac{\pi}{2}$ et  $\displaystyle \lim_{x\to +\infty}=+\dfrac{\pi}{2}$, donc d'après le théorème des valeurs intermédiaires l'équation $arctan(x)=0$ admet au moins une solution sur son intervalle de définition.
# Enfin, arctangente est strictement croissante sur son intervalle de définition, donc la solution est unique (théorème de la bijection).

# <codecell>

import matplotlib.pyplot as plt
import numpy as np

x = np.linspace(-10,10,1001)
plt.plot(x,np.arctan(x)) #Il faut arctan de numpy ici pour agir sur le tableau numpy x!

plt.title(r"Tracé de arctangente",fontsize=16)
plt.xlabel("x",fontsize=14)
plt.ylabel("y",fontsize=14)
plt.grid()
plt.show()

# <markdowncell>

# On peut raffiner le tracé, en affichant les valeurs en $\pi$ en ordonnées et en augmentant la taille de la figure et des ticks sur les axes ainsi:

# <codecell>

%matplotlib inline
import matplotlib.pyplot as plt

xmin = -10
xmax = 10
nb_ticks = 1000
x = [xmin+float(i*(xmax-xmin))/float(nb_ticks) for i in range(nb_ticks)] #liste des x

fig, ax = plt.subplots(figsize = (8, 6), dpi=400, frameon=False) #changement taille figure

ax.plot(x,[atan(elem) for elem in x], label = "atan") #x est une liste, on n'a pas besoin de numpy

ax.set_title(r"Trace de arctangente",fontsize=24)
ax.set_ylim(-pi/2, pi/2)
ax.set_yticks([-pi/2.0, -pi/4.0, 0.0, pi/4.0, pi/2.0])  #on fixe les ticks affichés en y
ax.set_yticklabels([r'$-\pi/2$', r'$-\pi/4$', '0.0', r'$\pi/4$', r'$\pi/2$']) #et on les affiche mieux
for item in (ax.get_xticklabels() + ax.get_yticklabels()):  #on modifie la taille des ticks
    item.set_fontsize(18)

ax.set_xlabel(r"$x$",fontsize=24)
ax.set_ylabel(r"$y$",fontsize=24)

ax.legend(loc=2, fontsize=18)
ax.grid(True)
plt.savefig('atan.pdf')

# <markdowncell>

# 2) Testons la méthode de Newton pour différentes valeurs de $u_0$

# <codecell>

newton(atan,lambda x: 1/(1+x**2), 1.2, 10**-6)

# <codecell>

newton(atan,lambda x: 1/(1+x**2), 1.4, 10**-6)

# <markdowncell>

# Certaines valeurs de $u_0$ font diverger la suite des ($u_n$).

# <markdowncell>

# 3) Demandons l'affichage des élements de la suite pour voir ce qu'il se passe

# <codecell>

newtliste(atan,lambda x: 1/(1+x**2), 1.2, 10**-6)

# <markdowncell>

# Quand tout se passe bien, les $u_n$ tendent vers 0, en changeant alternativement de signe, ce qui est logique compte tenu de la courbe de la fonction arctangente et de la manière dont la méthode de Newton fonctionne.

# <markdowncell>

# Retouchons *newtliste* afin que ce programme affiche au fur et à mesure les $u_n$. Cela nous permettra de voir ces termes même si le programme plante au final.

# <codecell>

def newtliste(f,fprime,u0,epsilon, verbose = False):
    u = u0
    liste_u = [u]
    while abs(f(u))>epsilon:
        u=u-f(u)/fprime(u)
        liste_u.append(u)
        if verbose: print(u, end="\t")
    return liste_u

# <codecell>

newtliste(atan,lambda x: 1/(1+x**2), 1.4, 10**-6, True)

# <markdowncell>

# Nous avons confirmation que les $u_n$ alternent toujours de signe mais divergent pour ce $u_0$. Le $u_0$ limite doit être tel que $u_{n+1}=-u_n$ pour tout $n$, c'est-à-dire que $u_0$ doit vérifier
# 
# $$u_0 - \dfrac{f(u_0)}{fprime(u_0)}=u_0 - \dfrac{arctan(u_0)}{1/(1+u_0^2)}=-u_0$$ 
# 
# ou encore $2u_0-(1+u_0^2)arctan(u_0)=0$. 
# 
# Comment déterminer $u_0$? Par la méthode de Newton bien sûr!

# <codecell>

u_0 = newton(lambda x: 2*x-(1+x**2)*atan(x),lambda x: 1-2*x*atan(x), 2, 10**-6)
print("La valeur limite de u_0 est:", u_0)

# <markdowncell>

# En conclusion, on voit que la méthode de Newton pose problème quand la dérivée de $f$ peut devenir faible. En effet, cela conduit à des tangentes quasi-horizontales, qui renvoient $u_{n+1}$ plus loin au lieu de le rapprocher de $u_n$!

# <headingcell level=3>

# Utilisation des bibliothèques Python

# <codecell>

import numpy as np
import scipy.optimize as spo

# <markdowncell>

# On peut avoir la liste de toutes les fonctions de scipy.optimize en tapant *dir(spo)*. 
# 
# Pour obtenir l'aide sur une fonction, on utilise *help(spo.bisect)* par exemple.

# <markdowncell>

# **Exercice 1**: On teste les différentes méthodes sur $f: x\to x^2-2$

# <codecell>

np.roots([1,0,-2])

# <codecell>

spo.bisect(sin,2.0,4.0)

# <codecell>

spo.newton(sin,4.0)

# <markdowncell>

# **Exercice 2**: On les compare entre elles et avec nos fonctions faites maison

# <codecell>

n_tests=10000
t=time()
np.roots([1,0,-2])
s=time()
print("Le temps de calcul pour la fonction x->x^2-2 par roots est:",time()-s)

# <codecell>

t=time()
dichotomie(sin,2.0,4.0,1e-12)
s=time()
print("Le temps de calcul pour la fonction x->x^2-2 par dicho maison est:",time()-s)

t=time()
spo.bisect(sin,2.0,4.0)
s=time()
print("Le temps de calcul pour la fonction x->x^2-2 par dicho scipy est:",time()-s)

# <codecell>

t=time()
newton(sin,cos,4.,1e-12)
s=time()
print("Le temps de calcul pour la fonction x->x^2-2 par Newton maison est:",time()-s)

t=time()
spo.newton(sin,4.,cos)
s=time()
print("Le temps de calcul pour la fonction x->x^2-2 par Newton scipy est:",time()-s)

# <markdowncell>

# **Exercice 3**: Quelques tracés

# <markdowncell>

# 1) On commence par la fonction $f: x\to x^2-2$

# <codecell>

import matplotlib.pyplot as plt
import numpy as np

fig, ax = plt.subplots(figsize = (8, 6), dpi=400, frameon=False)

x = np.linspace(-5,5,1001)

ax.plot(x,x**2-2)
ax.set_title(r"Trace de $f: x\to x^2-2$",fontsize=24)
ax.set_xlabel(r"$x$",fontsize=24)
ax.set_ylabel(r"$y$",fontsize=24)
for item in (ax.get_xticklabels() + ax.get_yticklabels()):
    item.set_fontsize(18)
ax.grid(True)

# <markdowncell>

# 2) On continue avec une visualisation graphique de la méthode de Newton

# <codecell>

from matplotlib import lines

liste_u = newtliste(lambda x:x**2-2.0,lambda x:2.0*x, 10, 10**-6)

fig, ax = plt.subplots(figsize = (10, 8), dpi=400, frameon=False)

# Tableaux (array) numpy pour le tracé.
u = np.array(liste_u)
x = np.linspace(0,10,1001)

# Tracés
ax.plot(x,x**2-2,'r',label=r"$f(x)$", lw=2)
ax.plot(u,u**2-2,'bo',label=r"$f(u_n)$", markersize=12)
ax.plot(u,[0]*u.size,'rD',label=r"$u_n$", markersize=12)

# Tracé des lignes en pointillés (fignolage)
for idx, crossing in enumerate(u[1:]):
    line = lines.Line2D([crossing,u[idx]],[0,u[idx]**2-2.0],linestyle='dashed',color='g', lw=2, label="tangentes")
    plt.axes().add_line(line)
    line = lines.Line2D([crossing,crossing],[0,crossing**2-2.0],linestyle='dashed',color='k', lw=1)
    plt.axes().add_line(line)
    
# Tracé de la ligne horizontale en y=0
plt.axhline(y=0,color='k')  

# Décor
ax.set_title(r"Methode de Newton sur la fonction $f:x \to x^2-2$",fontsize=24)
ax.set_xlabel(r"$x$",fontsize=24)
ax.set_ylabel(r"$y$",fontsize=24)
ax.set_xlim([1,5.5])
ax.set_ylim([-2,5.5**2])
ax.legend([r"$f(x)$",r"$f(u_n)$",r"$u_n$","tangentes"], loc=2, fontsize=22)
for item in (ax.get_xticklabels() + ax.get_yticklabels()):
    item.set_fontsize(18)
ax.grid(True)

# <markdowncell>

# 3) Tracé de l'erreur entre les termes des suites issues de la méthode dichotomique ($a_n$) et de Newton ($u_n$) et la valeur vraie ($\sqrt{2}$), en fonction du nombre d'itérations.

# <codecell>

liste_a = dicholiste(lambda x:x**2-2.0,0.0,20.0,10**(-15))
liste_u = newtliste(lambda x:x**2-2.0,lambda x:2*x, 10.0, 10**-15)

# tableaux (array) numpy pour le tracé.
a = np.array(liste_a)
u = np.array(liste_u)
xa = np.arange(0,len(a),1)   #on spécifie ici l'intervalle entre les points en dernier argument.
xu = np.arange(0,len(u),1)

# Tracés  
plt.plot(xa,np.abs(a-np.sqrt(2)),label="dichotomie")
plt.plot(xu,np.abs(u-np.sqrt(2)),label="Newton")

# Décor
plt.title(r"Erreur a la valeur vraie en fonction du nombre d'iterations",fontsize=16)
plt.xlabel("iterations",fontsize=16)
plt.ylabel("erreur",fontsize=16)
plt.legend()
plt.axis([1,15,0,1.5])
plt.show()

# <markdowncell>

# Ce graphe confirme les résultats précédents. La méthode de Newton converge plus rapidement vers le zéro recherché.
# 
# Si l'on fait un zoom, pour voir l'erreur la plus faible atteinte:

# <codecell>

import textwrap #sert juste à formater le titre pour que l'on voie le 10^-15 en y.

# Tracés  
plt.plot(xa,np.abs(a-np.sqrt(2)),label="dichotomie")
plt.plot(xu,np.abs(u-np.sqrt(2)),label="Newton")

# Décor
plt.title("\n".join(textwrap.wrap("Erreur a la valeur vraie en fonction du nombre d'iterations", 40)), fontsize=16)
plt.xlabel("iterations",fontsize=16)
plt.ylabel("erreur",fontsize=16)
plt.legend()
plt.axis([1,60,0,10**-15])
plt.tight_layout(pad=0.4, w_pad=10.5, h_pad=10.0)
plt.show()

# <markdowncell>

# On retrouve la limite à $0,2.10^{-15} = 2.10^{-16}$ due à la représentation des nombres sur 64 bits.

